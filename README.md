# ğŸš— Analyzing Car Reviews with LLMs

## ğŸ“Œ Project Overview
This project explores the use of **Large Language Models (LLMs)** for analyzing car reviews. It covers **sentiment classification, translation, extractive question answering, and summarization** to gain insights into customer feedback.

## ğŸ¯ Objectives
1. **Sentiment Analysis:** Classify reviews as **positive** or **negative** and evaluate performance using **accuracy and F1 score**.
2. **Translation:** Convert English reviews to Spanish and measure the translation quality using the **BLEU score**.
3. **Extractive QA:** Use a Question Answering (QA) model to extract relevant details from reviews.
4. **Summarization:** Generate concise summaries of car reviews.

## ğŸ› ï¸ Setup & Installation
### ğŸ”¹ Prerequisites
Ensure you have Python installed and set up the required dependencies:

```bash
pip install transformers torch datasets evaluate sacrebleu
```

### ğŸ”¹ Dataset Files
- **`car_reviews.csv`** - Contains car reviews along with sentiment labels.
- **`reference_translations.txt`** - Provides reference Spanish translations for BLEU score evaluation.

### ğŸ”¹ Running the Script
Execute the script to analyze car reviews:

```bash
script.ipynb
```

## ğŸ“Š Model Details
The following pre-trained models are used for different tasks:

| Task | Model Used |
|------|-----------|
| **Sentiment Analysis** | `distilbert-base-uncased-finetuned-sst-2-english` |
| **Translation** | `Helsinki-NLP/opus-mt-en-es` |
| **Extractive QA** | `deepset/minilm-uncased-squad2` |
| **Summarization** | `cnicu/t5-small-booksum` |

## ğŸ”— Future Enhancements
- **Fine-tuning models** for better accuracy on car reviews.
- Expanding support for **multiple languages**.
- Developing an **API or web-based tool** for real-time review analysis.

## ğŸ“œ License
This project is licensed under the **MIT License**.

---

ğŸš€ **Contributions are welcome!** If you find this useful, consider giving it a â­ on GitHub!
